Após desenvolver as condições necessárias para resolver o problema de controle
ótimo inicial, alguns problemas podem surgir. Como assumimos a existência de
controle ótimo, podemos encontrar uma função de controle mesmo quando não
haja. Também pode ser obtido um uma função que possua funcional com valor
infinito, algo que não é desejado. Portanto, se o funcional objetivo tiver
valor mais ou menos infinito, fizemos que o problema não tem solução. 

\section{Existência e Unicidade}

\begin{theorem}
    Seja $$J(u) := \int_{t_0}^{t_1} f(t,x(t),u(t))dt$$ 
    $$\text{sujeito a } x'(t) = g(t,x(t),u(t)), x(t_0) = x_0.$$ 
    Suponha que $f(t,x,u)$ e $g(t,x,u)$ sejam continuamente diferenciáveis nos
    três argumentos e côncavos no segundo e terceiro argumentos. Suponha que
    $u^*$ é um controle, com estado associado $x^*$, e $\la$ uma função
    diferenciável por partes, tal que $t_0 \le t \le t_1$: 
    \begin{subequations}
        \label{eq:conditions}
        \begin{align}
            f_u + \la g_u &= 0, \label{rel1} \\
            \la ' &= - (f_x + \la g_x),  \label{rel2} \\ 
            \la(t_1) &= 0, \label{rel3} \\
            \la(t) &\ge 0. \label{rel4}
        \end{align}
    \end{subequations}
    Então, para todos os controles $u$, $J(u^*) \ge J(u)$. 
\end{theorem}

\begin{proof}
    Seja $u$ um controle qualquer. Assim, usando a concavidade de $f$,
    \begin{equation}
        \label{eq:first-result}
        \begin{split}
            J(u^*) - J(u) &= \int_{t_0}^{t_1} f(t, x^*, u^*) - f(t,x,u) dt \\
            &\ge \int_{t_0}^{t_1} (x^{*}(t) - x(t))f_x(t, x^*, u^*) \\ 
            &~~+ (u^*(t) - u(t))f_u(t, x^*, u^*)dt
        \end{split}
    \end{equation}
    Aplicando \refeq{rel1} e \refeq{rel2} ao último termo de
    \refeq{eq:first-result}, 
    \begin{equation*}
        \begin{split}
            \int_{t_0}^{t_1} &(x^{*}(t) - x(t))(-\la(t)g_x(t,x^*, u^*) - \la '(t)) \\ 
            &+ (u^*(t) - u(t))(-\la(t)g_u(t,x^*, u^*))dt.
        \end{split}
    \end{equation*}
    Integrando por partes, com $\la(t_1) = 0$ e $x(t_0) = x^*(t_0)$, vemos que
    \begin{equation*}
        \begin{split}
            \int_{t_0}^{t_1} -\la '(t)(x^*(t) - x(t))dt &= -\cancel{(x^*(t) - x(t))\la(t)\bigg\rvert_{t_0}^{t_1}} \\ 
            &~~~~+ \int_{t_0}^{t_1}\la(t)(x^*(t) - x(t))'dt \\
            &= \int_{t_0}^{t_1}\la(t)(g(t,x^*(t),u^*(t)) - g(t,x(t),u(t)))dt
        \end{split}
    \end{equation*}
    Substituindo e usando tanto a concavidade de $g$ quanto \refeq{rel4},
    \begin{equation*}
        \begin{split}
            J(u^*) - J(u) \ge \int_{t_0}^{t_1} &\la(t)[g(t, x^*, u^*) - g(t,x,u) - \\
            &(x^* - x)g_x(t,x^*, u^*) - (u^* - u)g_u(t, x^*, u^*)]dt \\
            \ge 0 ~~~~&
        \end{split}
    \end{equation*}
\end{proof}

Falta garantir que $J(u^*)$ seja finito. Para isso, algumas restrições sobre
$f$ e/ou $g$ são necessárias. O próximo teorema é um exemplo sobre isso. 

\begin{theorem}
    Seja $u \in L([t_0,t_1];\mathbb{R})$. Suponha que $f$ é uma função convexa em $u$, e existam constantes $C_4$ e $C_1$,$C_2$,$C_3 >0$ e $\beta > 1$, tal
    que, $\forall t \in [t_0, t_1], x, x_1, u \in \mathbb{R}$. 
    \begin{equation*}
        \begin{cases}
            g(t,x,u) = \alpha (t,x) + \beta (t,x)u \\
            |g(t,x,u)| \leq C_1(1 + |x| + |u|) \\
            |g(t,x_1,u) - g(t,x,u)| \leq C_2|x_1 - x|(1 + |u|) \\
            f(t,x,u) \geq C_3|u|^{\beta} - C_4
        \end{cases}
    \end{equation*}
    Então existe um controle ótimo $u^*$ maximizando $J(u)$ com $J(u^*)$
    finito. 
\end{theorem}

Em problemas de minimização, $g$ seria côncava e a desigualdade de $f$ é
revertida. Podemos extender as condições necessárias para funções de controle
Lebesgue integráveis, mas isso não é feito aqui. Alguns resultados de
existência de controle ótimo podem ser encontrados em \cite{filippov1962}. 

\Space

\textbf{Unicidade:} Unicidade de soluções do sistema de otimalidade implica
unicidade do controle ótimo, quando ele existir. Em geral, podemos provar a
unicidade de soluções do sistema de otimalidade em intervalos de tempo curtos.
A volta nem sempre é verdadeira, isto é, unicidade do controle ótimo não garante a
unicidade do sistema. 

Os exemplos e laboratórios satisfazem as condições de existência e unicidade
para intervalos de tempo pequenos. Portanto, resolver através das condições
necessárias já é suficiente. 

\section{Interpretação da Adjunta}

Defina 
$$
V(x_0, t_0) := \max_u \int_{t_0}^{t_1} f(t,x(t), u(t)) dt
$$
$$
\text{sujeito a } x'(t) = g(t,x,u), x(t_0) = x_0.
$$
Estabelecemos que 
$$\frac{\partial V}{\partial x}(x_0, t_0) = \lim_{\e \to 0} \frac{V(x_0 + \e,
t_0) - V(x_0,t_0)}{\e} = \la(t_0).$$

Podemos relacionar, então, a função adjunta à variação marginal da função
custo/lucro com respeito ao estado. Na verdade, essa aproximação é
válida para todo tempo $t$ \cite[136-139]{kamien2012dynamic}. Podemos aproximar: 
\begin{equation*}
    V(x_0 + \e,t_0) \approx V(x_0,t_0) + \e\la(t_0). 
\end{equation*}
Com $\e = 1$, podemos ver que ao adicionar uma unidade à condição inicial,
$\la(t_0)$ será adicionado ao lucro resultante. portanto é o valor adicional
associado ao incremento unitário no estado. 

\section{Princípio da Otimalidade}

É um resultado importante sobre otimização de um sistema sobre um subintervalo do
intervalo original e, em particular, como o controle ótimo nesse subintervalo
se relaciona com o controle no intervalo inteiro. 

\begin{theorem}
    Considere $u^*$ o controle ótimo associado ao estado $x^*$ para o problema
    $$
    \max_u J(u) = \max_u \int_{t_0}^{t_1} f(t, x(t), u(t)) dt 
    $$
    $$
    \text{sujeito a  }x'(t) = g(t, x(t), u(t)), x(t_0) = x_0.
    $$
    Seja $\hat{t} \in (t_0, t_1)$ fixo. Então as
    funções $u^*$ e $x^*$ restritas ao intervalo $[\hat{t},t_1]$, indicadas
    por $\hat{u}^*$ e $\hat{x}^*$, formam uma solução ótima para o problema 
    $$
    \max_u \hat{J}(u) = \max_u \int_{\hat{t}}^{t_1} f(t, x(t), u(t)) dt 
    $$
    $$
    \text{sujeito a  }x'(t) = g(t, x(t), u(t)), x(\hat{t}) = x^*(\hat{t}).
    $$
    Além disso, se $u^*$ é controle ótimo único, então
    $\hat{u}^*$ é também. 
\end{theorem}

\begin{proof}
    Esta prova se dá por contradição. Suponha que $\hat{u}^*$ não seja ótimo,
    isto é, exista uma função de controle $\hat{u}_1$ no intervalo $[\hat{t},
    t_1]$ tal que $\hat{J}(\hat{u}_1) > \hat{J}(\hat{u}^*)$. Defina 
    $$u_1(t) = 
    \begin{cases}
        u^*(t), &t \in [t_0, \hat{t}] \\
        \hat{u}_1(t), &t \in [\hat{t}, t_1]
    \end{cases}
    $$
    Seja $x_1$ o estado associado a $u_1$. Assim 
    \begin{equation*}
        \begin{split}
            J(u_1) - J(u^*) &= \left(\int_{t_0}^{\hat{t}} f(t,x_1,u_1)dt +
            \hat{J}(\hat{u}_1)\right) - \left(\int_{t_0}^{\hat{t}} f(t,x^*,u^*)dt +
            \hat{J}(\hat{u}^*)\right) \\
            &= \hat{J}(\hat{u}_1) - \hat{J}(\hat{u}^*) > 0 
        \end{split}        
    \end{equation*}
    dado que os controles são iguais no intervalo $[t_0, \hat{t}]$. Isso contradiz a hipótese inicial de que $u^*$ é controle ótimo. 
\end{proof}

\begin{remark}
    Nada pode ser dito sobre o intervalo $[t_0, \hat{t}]$. Em particular sabemos que o controle ótimo não será, necessariamente, o controle do problema restrito a esse intervalo, como veremos nos Exemplos. 
\end{remark}

\section{Os Problemas Autônomo e Hamiltoniano}

Os seguintes teoremas são menos utilizados, mas são importantes de ser notadas. A demonstração não é descrita no texto. 

\begin{theorem}
    O Hamiltoniano é uma função contínua Lipschitz do tempo $t$ no caminho
    ótimo $(u^*, x^*)$. 
\end{theorem}

\begin{definition}[Autônomo]
    Se um problema de controle ótimo não tem dependência explícita do tempo,
    ele é dito autônomo. Isso significa que $f$ e $g$, em nossa notação, são
    funções apenas de $x$ e $u$. 
\end{definition}

\begin{theorem}
    Se um problema de controle ótimo é autônomo, então o Hamiltoniano é uma
    função constante do tempo ao longo da solução ótima. 
\end{theorem}

\section{Exemplos}

\begin{example}
    Queremos resolver o problema 
    $$
    \min_u \int_{t_0}^{t_1} x(t) + \frac{1}{2}u(t)^2 dt
    $$
    $$  
    \text{sujeito a  }x'(t) = x(t) + u(t), x(0) = \frac{1}{2}e^2 - 1
    $$
    no intervalo $[0,2]$ e, posteriormente, no intervalo $[1,2]$.
\end{example}

Observe inicialmente que $f$ e $g$ são continuamente diferenciáveis e convexos no segundo 
e terceiro argumentos, dado que o problema é de minimização. Vamos então conferir as condições 
necessárias e, então, saberemos que $J(u^*) \le J(u)$ para toda função de controle $u$, pelo 
teorema de existência. 

\Space

O Hamiltoniano é 
$$
H = x + \frac{1}{2}u^2 + x \la + u \la
$$
A equação adjunta é dada por 
$$
\la ' = - H_x = -1 - \la, \la(2) = 0 \implies \la(t) = e^{2-t} -1 \ge 0,
$$
A condição de otimalidade é dada por 
$$
H_u = u + \la = 0 \implies u^*(t) = -\la(t) = 1 - e^{2-t} 
$$
E, portanto 
$$
x'(t) - x(t) = 1 - e^{2-t} \implies x(t) = Ce^t + \frac{1}{2}e^{2-t} - 1
$$
Usando a condição inicial 
$$
\frac{1}{2}e^2 - 1 = C + \frac{1}{2}e^{2} - 1 \implies x^*(t) =  \frac{1}{2}e^{2-t} - 1   
$$

Considerando o intervalo em $[1,2]$, vemos que $\hat{u}^* = u^*$ em $[1,2]$. Se fôssemos resolver 
fazendo as contas, veja que todos os passos poderiam ser repetidos, com exceção de que $x(1) = \frac{1}{2}e - 1$, 
o que não mudaria a solução. 

\begin{example}
    Considere o problema acima, mas no intervalo $[0,1]$. 
\end{example}

O Hamiltoniano é o mesmo e $u^*(t) = -\la(t)$. Mas a condição de transversalidade é diferente: 
$\la(1) = 0 \implies \la(t) = e^{1-t} - 1 \text{ e } u^{*}(t) = 1 - e^{1-t}$. 
Ao usarmos a equação do estado, obteremos que 
$$
x^*(t) = \frac{1}{2}e^{1-t} - 1 + \frac{1}{2}(e^2 - e)e^t
$$
Note que a solução é diferente da anterior restrita a $[0,1]$. 