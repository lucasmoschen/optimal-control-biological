\section{Preliminares}

Alguns conceitos e teoremas básicos de análise que serão utilizados durante o texto e
podem ser encontrados em diversos livros: 

\begin{enumerate}
    \item \label{piecewise-continuous} \textbf{Continuidade por partes:} Função contínua em cada
    ponto em que é definida, exceto em uma quantidade finita deles, e igual a
    seu limite à esquerda ou à direita em cada ponto. Logo, podemos ter
    finitos saltos, mas não podemos ter pontos isolados. 
    \item \textbf{Diferenciável por partes:} Função contínua que é
    diferenciável em cada ponto em que é definida, exceto em uma quantidade
    finita deles. Além disso, sua derivada é contínua sempre que definida. 
    \item \textbf{Convexidade:} A função $k$ é convexa se $\forall 0 \leq
    \alpha \leq 1$ e para qualquer $a \leq t_1,t_2 \leq b$, $\alpha k(t_1) + (1 -
    \alpha)k(t_2) \geq k(\alpha t_1 + (1 - \alpha)t_2)$. A definição é
    equivalente para funções de duas ou mais variáveis. Ela será côncava se
    $-k$ for convexa. 
    \item \textbf{Lipschitz:} Função $k$ em que existe $c$ constante tal que
    $|k(t_1) - k(t_2)| \leq c|t_1 - t_2|$, para todos os pontos do domínio de
    $k$. 
    \item \textbf{Teorema do Valor Médio:} Seja $k$ contínua em $[a,b]$ e
    diferenciável em $(a,b)$. Então existe $x_0 \in (a,b)$ tal que $k(b) -
    k(a) = k'(x_0)(b - a)$. 
    \item \label{dominated-convergence} \textbf{Teorema da Convergência Dominada:} Considere uma sequência
    $\{f_n\}$ dominada por uma função Lebesgue integrável $g$. Suponha que
    essa sequência converge ponto a ponto para uma função $f$. Então $f$ é
    integrável e $\lim_{n \to \infty} \int_S f_n d\mu = \int_S f d\mu$.
\end{enumerate}

\begin{remark}
    Se $x$ é solução da equação diferencial $x'(t) = g(t, x(t), u(t))$, em que
    $g$ é contínua nas três variáveis, então $x$ é diferenciável sempre que
    $u$ é contínua. Se $u$ for contínua por partes, então $x$ será
    diferenciável por partes. 
\end{remark}

\begin{exercise}
    Se $k: I \subset \mathbb{R} \to \mathbb{R}$ é diferenciável por partes em
    um intervalo $I$ limitado, $k$ é Lipschitz. 
\end{exercise}

\section{Condições necessárias para o problema básico} 

Considere $u(t)$ uma variável de controle e $x(t)$ variável de estado que
satisfaz 

\begin{equation}
    \label{initial-system}
    x'(t) = g(t,x(t),u(t)). 
\end{equation}

Podemos ver a relação entre essas variáveis
como $u(t) \mapsto x = x(u)$.  O problema básico do controle ótimo é encontrar
uma função de controle contínua por partes \ref{piecewise-continuous} $u(t)$ que
maximize um dado funcional objetivo 

\begin{equation}
    \label{objetivo}
    J(u) := \int_{t_0}^{t_1} f(t,x(t),u(t))dt    
\end{equation}

Nos problemas encontrados nesse texto, $f$ e $g$ são sempre continuamente
diferenciáveis. Para isso, se $u^{*}(t)$ e $x^*(t) = x(u^*(t))$ são
argumentos ótimos, podemos extrair condições necessárias para o problema. No
capítulo \ref{ch:2}, são discutidas as condições suficientes. 

\label{adjoint-function}
\textbf{Função Adjunta:} proposta similar aos multiplicadores de Lagrange para
o cálculo multivariado. $\lambda : [t_0,t_1] \to \mathbb{R}$ é diferenciável
por partes e deve satisfazer algumas condições que serão derivadas
posteriormente. 

Assuma a existência de $u^*$ e $x^*$ em um problema de maximização. Nesse caso, $J(u) \leq J(u^*)
< \infty$, para todo controle $u$. Seja $h(t)$ uma função contínua por partes
e $\e \in \mathbb{R}$.  Então:
\begin{equation*}
    u^{\e}(t) = u^*(t) + \e h(t), u^{\e} \mapsto x^{\e}, 
\end{equation*}
tal que $x^{\e}$ satisfaz \ref{initial-system} sempre que $u^{\e}$ é contínua. Consideramos $x^{\e}(t_0) = x_0$.

Para todo $t$, quando $\e \to 0$, temos que $u^{\e}(t) \to u^*(t)$, pela
própria definição. Além disso, 
\begin{equation*}
    \frac{\partial u^{\e}(t)}{\partial \e}\bigg\rvert_{\e = 0} = h(t).
\end{equation*}
Como a função $g$ é continuamente diferenciável, também ocorre que, para todo
$t$ fixo, 
\begin{equation*}
        x^{\e}(t) \to x^*(t) \text{ e }
        \frac{\partial}{\partial \e}x^{\e}(t)\bigg\rvert_{\e = 0} \text{ existe.}
\end{equation*}
\begin{remark}
    Se for difícil enxergar isso, pense que 
    $$x^{\e}(t) = x_0 + \int_{t_0}^t
    g(s, x^{\e}(s), u^{\e}(s))ds$$
\end{remark}
Seja $\la(t)$ a função adjunta (\ref{adjoint-function}) no intervalo $[t_0, t_1]$. Pelo Teorema Fundamental do Cálculo, 
\begin{equation*}
    \int_{t_0}^{t_1} \frac{d}{dt}[\la(t)x^{\e}(t)]dt = \la(t_1)x^{\e}(t_1) - \la(t_0)x^{\e}(t_0),
\end{equation*}
e, portanto, exceto em uma finidade de pontos,
\begin{equation*}
    \begin{split}
        J(u^{\e}) &= \int_{t_0}^{t_1} [f(t,x^{\e}(t), u^{\e}(t)) + \frac{d}{dt}(\la(t)x^{\e}(t))]dt \\
        &+ \la(t_0)x_0 - \la(t_1)x^{\e}(t_1) \\
        &= \int_{t_0}^{t_1} [f(t, x^{\e}(t), u^{\e}(t)) + \la '(t)x^{\e}(t) + \la(t)\overbrace{g(t,x^{\e}(t), u^{\e}(t))}^{(x^{\e})'(t)}] dt \\
        &+ \la(t_0)x_0 - \la(t_1)x^{\e}(t_1).
    \end{split}
\end{equation*}

Sabemos que 
\begin{equation*}
    0 = \frac{d}{d\e} J(u^{\e})\bigg\rvert_{\e = 0} = \lim_{\e \to 0} \frac{J(u^{\e}) - J(u^{*})}{\e}, 
\end{equation*}
pois $J(u^*)$ é máximo. Desta maneira, como o integrando é diferenciável por
partes e o intervalo é compacto, pelo Teorema da Convergência Dominada
(\ref{dominated-convergence}), podemos mover o limite para dentro da integral.
Em especial, podemos mover a própria derivada. 

\begin{equation*}
    \label{eq1}
    \begin{split}
        0 &= \frac{d}{d\epsilon} J(u^{\epsilon})\bigg\rvert_{\e = 0} \\ 
        &= \int_{t_0}^{t_1} \frac{\partial}{\partial \e}\left[f(t, x^{\e}(t), u^{\e}(t)) + \la '(t)x^{\e}(t) + \la(t)g(t,x^{\e}(t), u^{\e}(t))dt\right]\bigg\rvert_{\e = 0}\\ 
        &- \la(t_1)\frac{\partial x^{\e}}{\e}(t_1)\bigg\rvert_{\e = 0} \\
        &= \int_{t_0}^{t_1} \left[(f_x + \la(t)g_x + \la '(t))\frac{\partial x^{\e}}{\partial\e}(t)\bigg\rvert_{\e = 0} + (f_u + \la(t)g_u)h(t)\right]dt \\
        &- \la(t_1)\frac{\partial x^{\e}}{\e}(t_1)\bigg\rvert_{\e = 0},
    \end{split}
\end{equation*}
onde os termos de $f_x, f_u, g_x, \text{e} g_u$ são $(t, x^*(t), u^*(t))$. 
Para garantir que ocorra a igualdade citada acima, definimos 

\begin{definition}[Hamiltoniano]
    \label{hamiltonian}
    \begin{equation*}
        H(t,x,u,\la) = f(t,x,u) + \la g(t, x,u)
    \end{equation*}
\end{definition}

Para obter a igualdade acima para qualquer função $h$, precisamos que as condições abaixo sejam
satisfeitas e, em particular estamos maximizando $H$ com respeito a $u$ em $u^*$ e, então: 

\begin{equation}
    \begin{cases}
        \dfrac{\partial H}{\partial u} \bigg\rvert_{u = u^{*}} = f_u + \la g_u = 0, &\text{(condição de otimalidade)}\\ \\
        \dfrac{\partial H}{\partial x} \bigg\rvert_{x = x^*} = - \la ' = -(f_x + \la g_x), &\text{(equação adjunta)} \\ \\
        \dfrac{\partial H}{\partial \la} = x' \\ \\
        \la(t_1) = 0, &\text{(condição de transversalidade)}
    \end{cases}    
\end{equation}

\section{Princípio Máximo de Pontryagin}
\label{pontryagin}

\begin{theorem}
    Se $u^*(t)$ e $x^*(t)$ são ótimos para o problema de controle ótimo, então
    existe $\la(t)$ adjunta diferenciável por partes tal que 
    \begin{equation}
        \label{inequality-hamiltonian}
        H(t, x^*(t), u(t), \la(t)) \le H(t, x^*(t), u^*(t), \la(t))
    \end{equation}    
    para todas as funções de controle $u$ e cada $t$, onde 
    $$
    H = f(t, x(t), u(t)) + \la(t)g(t, x(t), u(t))
    $$
    e
    $$
    \la '(t) = \dfrac{\partial H(t, x^*(t), u^*(t), \la (t))}{\partial x} 
    $$
    $$
    \la(t_1) = 0
    $$
\end{theorem}  

Já mostramos que $H_u = 0$ em $u^*$ para cada $t$. De fato existe um ponto
crítico em $u^*$ e faltaria provar que ele é máximo. A demonstração para isso
é complicada e é omitida do texto. 

\begin{theorem}
    \label{theorem-inequality}
    Suponha que $f$ e $g$ sejam continuamente diferenciáveis nos três
    argumentos e côncava em $u$. Suponha que $u^*$ seja o controle ótimo
    associado ao estado $x^*$ e que $\la$ seja uma função diferenciável por
    partes não negativa. Suponha que $\forall t_0 \le t \le t_1$
    $$
    0 = H_u(t, x^*(t), u^*(t), \la(t))
    $$
    Então vale \refeq{inequality-hamiltonian}.
\end{theorem}

\begin{proof}
    Tome uma função $u$ contínua por partes e $t \in [t_0, t_1]$. Então 
    \begin{equation*}
        \begin{split}
            H(t, &x^*(t), u^*(t), \la(t)) - H(t, x^*(t), u(t), \la(t))  \\ 
            &= \left[f(t,x^*(t), u^*(t)) + \la(t)g(t,x^*(t), u^*(t))\right] \\
            &~~~~- \left[f(t,x^*(t), u(t)) + \la(t)g(t,x^*(t), u(t))\right] \\ 
            &= \left[f(t,x^*(t), u^*(t)) - f(t,x^*(t), u(t)) \right] \\
            &~~~~+ \la(t)\left[g(t,x^*(t), u^*(t)) - g(t,x^*(t), u(t))\right] \\
            &\ge (u^*(t) - u(t))f_u(t,x^*(t), u^*(t)) + \la(t)(u^*(t) - u(t))g_u(t,x^*(t),u^*(t)) \\ 
            &= (u^*(t) - u(t))H_u(t,x^*(t), u^*(t),\la(t)) = 0,
        \end{split}
    \end{equation*}
    onde a desigualdade vem da concavidade de $f$ e $g$ e $\la(t) \ge 0$. 
\end{proof}

\begin{remark}
    Convertemos o problema de encontrar uma função de controle que maximize um
    funcional para um problema de maximizar pontualmente o Hamiltoniano com
    respeito a um controle. 
\end{remark}

\begin{remark}
    A concavidade de $H$ nos fala sobre o tipo de problema que está sendo
    considerado: se a segunda derivada é negativa em $u^*$, tem-se um problema de
    maximização, enquanto se ela for positiva, o problema é de minimização. 
\end{remark}

\section{Exemplos}

\begin{example}
    \begin{equation*}
        \min_u \int_1^2 tu(t)^2 + t^2x(t) dt
    \end{equation*}
    \begin{equation*}
        \text{sujeito a} x'(t) = -u(t), x(1) = 1
    \end{equation*}
\end{example}

Primeiro definimos o Hamiltoniano 
$$
H = [tu(t)^2 + t^2 x(t)] + \lambda(- u(t))
$$
Agora vamos observar as condições sobre o Hamiltoniano:

\begin{enumerate}
    \item \textit{Otimalidade}: $H_u = 0 \implies 2tu^*(t) - \la \implies
    u^*(t) = \dfrac{\la}{2t}$
    \item \textit{Equação adjunta}: $H_x = t^2 = - \la ' \implies \la(t) = -
    \frac{1}{3}t^3 + C$
    \item \textit{Transversalidade}: $\la(2) = 0 \implies C = \frac{8}{3}
    \implies \la(t) = - \frac{1}{3}t^3 + \frac{8}{3}$.
\end{enumerate}

Com essas condições, podemos ver que o controle ótimo é dado por 

$$
u^*(t) = -\frac{1}{6}t^2 + \frac{8}{6}t^{-1}
$$

Note que não provamos a existência de tal controle, o que está sendo feito é:
supondo a existência de um controle ótimo, usamos os teoremas da seção
\ref{pontryagin} para encontrar a função adjunta e, assim, encontrar as
funções ótimas que resolvem o problema. Além disso, podemos observar que as
condições do Teorema \ref{theorem-inequality} são satisfeitas. 

Para encontrar o estado, resolvemos $x'(t) = - u(t)$ e temos:

$$
x^*(t) = \frac{1}{18}t^3 - \frac{8}{6}\ln(t) + D,
$$

tal que $x^*(1) = 1 = \frac{1}{18} + D$ e, portanto 

$$
x^*(t) = \frac{1}{18}t^3 - \frac{8}{6}\ln(t) + \frac{17}{18}
$$

\begin{example}[Efeito Alle]
    Formule um problema de controle ótimo para uma população com um termo de
    crescimento de efeito Allee, em que o controle é a proporção da população
    caçada. Escolha um funcional objetivo que maximize a receita da caça
    enquanto minimiza o seu custo. A receita é a integral da quantidade caçada
    no tempo. O custo tem  formato quadrático. 
\end{example}

O efeito Allee descreve um crescimento conforme a equação 

\begin{equation}
    x'(t) = rx(t)\left(\frac{x(t)}{x_{min}} - 1\right)\left(1 - \frac{x(t)}{x_{max}}\right)
\end{equation}

Nessa equação, temos um limiar $x_{min}$ e uma capacidade de carga do ambiente
$x_{max}$. Se $x(0) > x_{min}$, a solução $x(t)$ se aproxima de $x_{max}$. Se ela começa
abaixo, ela decairá para 0. Como o crescimento líquido é negativo em níveis
populacionais baixos, a população não consegue se manter e morre. O
crescimento per capita também não é monotonicamente decrescente e mostra o
efeito que chamamos de Allee, figura \ref{Fig1:allee-effect}. Para entender mais sobre o efeito Allee, 
sugere-se \cite{kot2001elements}. 

\begin{figure}[!ht]
    \center
    \input{files/allee_effect.tex}
    \caption{Efeito Allee}
    \label{Fig1:allee-effect}
\end{figure}

Existe uma certa liberdade em como fazer essa modelagem. Mas uma possível
proposta é a seguinte: Se $x(t)$ é o tamanho da população no tempo $t$ e
$u(t)$ é a proporção da população caçada, a variação da população é dada por

$$
x'(t) = rx(t)\left(\frac{x(t)}{x_{min}} - 1\right)\left(1 - \frac{x(t)}{x_{max}}\right) - u(t)x(t)
$$

$$x(0) = \frac{x_{min} + x_{max}}{2}$$

Para definir um objetivo, queremos maximizar a receita, que é dada por, se $T$
for o final do período,
$$
R(u) = \int_0^T u(t)x(t)dt
$$
E queremos minimizar o custo da caça, que é assumido como quadrático: 
$$
C(u) = \int_0^T [u(t)x(t)]^2dt
$$
Queremos portanto 
$$
\max_u [R(u) - C(u)]
$$